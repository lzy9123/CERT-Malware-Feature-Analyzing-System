#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Jul 1 03:57:49 2019
@author: zhiyuli
Debug


Modified on Mon Jul 15 21:42:39 2019
Debug
@author: zhiyuli
"""
import numpy as np
from itertools import islice
class Pipeline:
    """Pipeline class

        In this class, the data will be processed
        step by step as a pipeline

    """
    def __init__(self, steps, verbose=True):
        """Initial pipeline class
            
            Use linear regression model to train the training data.

            Args:
            steps: a list of function, model or data

            return:
            none

            Example:
            >>>> from utils.Pipeline import Pipeline
            >>>> from utils.model_zoo import MLP
            >>>> # Using pipeline for training
            >>>> def preprocess(X):
            >>>>     return X/ np.mean(X)

            >>>> step = [   
            >>>>     preprocess,
            >>>>     MLP('Neural Networks')
            >>>> ]

            >>>> pipeline1 = Pipeline(step)
            >>>> pipeline1.fit(train_data[['size', 'vt_meta_size']], train_data['isShared-lib'],
            >>>>     solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)
            >>>> # Neural Networks training time is 0:00:00.079824
            >>>> 
            >>>> # get processing class via index
            >>>> clf = pipeline1[1]

            >>>> # use pipeline to predict (default function call)
            >>>> predict_data = pipeline1[:](train_data[['size', 'vt_meta_size']])
            >>>> 
            >>>> # use pipeline to analysis
            >>>> step2 = [   
            >>>>     ('a', preprocess),
            >>>>     ('b', clf),
            >>>>     ('d', predict_data),
            >>>>     ('e', similiarity)
            >>>> ]
            >>>> pipeline2 = Pipeline(step2)
            >>>> pipeline2(train_data[['size', 'vt_meta_size']])
            >>>> # array([[1.]])
                
        """

        self.steps = steps
        self._validate_steps()
        self.verbose = verbose

    def run(self, X):
        """run function
            
            process data step by step
            step includes Models, function or adding data
            if step is Models, process data with predict
            if step is function, call the function with data
            if another piece of data is parsed, add as a new tuple

            Args: 
            X: input data

            return:
            X: output data
            
        """

        for _, _, step in self._iter():
            if step.__class__.__name__ in ("Models", "function", "method"):
                X = step(X)
            elif isinstance(step, np.ndarray):
                X = (X, step)
            elif isinstance(step, list):
                X = (X, np.array(step))
            elif step.__class__.__name__  in ("plot", "Analyser"):
                step(X)
                X = None
        return X

    def _validate_steps(self):
        """validate_steps 
            check whether steps are allowed

        """
        
        for idx, _, step in self._iter():
            if step.__class__.__name__ in ("function", "method", "ndarray", "list", "Models"):
                continue
            elif step.__class__.__name__  in ("plot", "Analyser"):
                if idx != len(self.steps) - 1:
                    raise TypeError("Models, plot or Analyser are only allowed to be put at the end of Pipeline.")
            else:
                raise TypeError("Models, function, method, ndarray, list, plot, Analyser are allowed in Pipeline." 
                        "'step' (type %s) dosen't" %
                                (type(step)))

                    

    def _iter(self):
        """_iter

            iterator of steps

            return:
                iterator
            
        """
        steps = self.steps
        if isinstance(steps[0], tuple) :
            for idx, (name, step) in enumerate(islice(steps, 0, len(steps))):
                yield idx, name, step
        else:
            for idx, step in enumerate(islice(steps, 0, len(steps))):
                yield idx, str(idx), step

    @property
    def named_steps(self):
        """named_steps

            get name step dictionary
        """
        return dict(self.steps)

    def _get_item_by_index(self, ind):
        """_get_item_by_index

            get item by index or key name
            
            args:
                ind: index or key
            
            return:
            corresponding object in the steps
            
        """

        try:
            est = self.named_steps[ind]
        except (KeyError, TypeError) as error:
            # Not an int, try get step by name
            est = self.steps[ind]
            if isinstance(est, tuple):
                return est[1]
            return est
        return est

    def __getitem__(self, ind):
        """__getitem__
            
            __getitem__ is used to implement calls like class[key]

            args:
                ind

            return 
                corresponding object in the steps

        """
        if isinstance(ind, slice):
            return self.__class__(self.steps[ind])
        else:
            return self._get_item_by_index(ind)
        

    def fit(self, x_train, y_train = None, **parameter):
        """fit
            
            fit is used to train the model with pipeline

            args:
                x_train: training variables
                y_train: labels (can be none for 
                    Non-supervised learning)
                parameter: other parameters used in training
        """
        for idx, name, step in self._iter():
            if step.__class__.__name__ == "Models":
                step.fit(x_train, y_train, **parameter)
            else:
                x_train = step(x_train)


    def __call__(self, data):
        """__call__
             special method triggered when 
             the instance of a class is called.
        """

        return self.run(data)

                



